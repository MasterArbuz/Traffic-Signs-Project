// 1.
import gc, os, cv2, PIL, torch
import torchvision as tv
import torch.nn as nn
import torchsummary as ts
import numpy as np
import pandas as pd
import plotly.express as px
import matplotlib.pyplot as plt
from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report


// 2.
labels_df = pd.read_csv('/content/drive/MyDrive/dataset/pro/labels.csv')
labels_df


// 3.
x , y = [] , [] 
data_dir = '/content/drive/MyDrive/dataset/pro/pls'
for folder in range(43):
    folder_path = os.path.join(data_dir,str(folder))
    for i,img in enumerate(os.listdir(folder_path)):
        img_path = os.path.join(folder_path,img)
        img_tensor = tv.transforms.ToTensor()(PIL.Image.open(img_path))
        x.append(img_tensor.tolist()) 
        y.append(folder)
    print('folder of label',folder,'images loaded. Number of samples :',i+1)
x = np.array(x)
y = np.array(y)


//4.
np.unique(y,return_counts=True)
x = x.reshape(x.shape[0],3*32*32)
x,y = RandomOverSampler().fit_resample(x,y)
x = x.reshape(x.shape[0],3,32,32) # reshaped again as it was
x.shape, y.shape


// 5.
np.unique(y,return_counts=True)
xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,stratify=y)
del x,y
gc.collect()
xtrain.shape, xtest.shape, ytrain.shape, ytest.shape


// 6.
plt.figure(figsize=(20,20)) 
plt.imshow(tv.utils.make_grid(torch.tensor(xtrain[:100]),nrow=10).permute(1,2,0))
plt.axis('off')
plt.show()
print('\n\nLabels of the above images :\n')
ytrain[:100]


// 7.
xtrain = torch.from_numpy(xtrain) 
ytrain = torch.from_numpy(ytrain)
xtest = torch.from_numpy(xtest)
ytest = torch.from_numpy(ytest)


// 8.
model = nn.Sequential(
                        # 1st convolutional network Layers
                        nn.Conv2d(3,16,(2,2),(1,1),'same'),   # Convolution
                        nn.BatchNorm2d(16),                   # Normalization 
                        nn.ReLU(True),                       # Activation
                        nn.MaxPool2d((2,2)),                 # Pooling
    
                        # 2nd convolutional network Layers
                        nn.Conv2d(16,32,(2,2),(1,1),'same'),  # Convolution
                        nn.BatchNorm2d(32),                  # Normalization 
                        nn.ReLU(True),                       # Activation
                        nn.MaxPool2d((2,2)),                 # Pooling
    
                        # 3rd convolutional network Layers
                        nn.Conv2d(32,64,(2,2),(1,1),'same'), # Convolution
                        nn.BatchNorm2d(64),                  # Normalization 
                        nn.ReLU(True),                       # Activation
                        nn.MaxPool2d((2,2)),                 # Pooling

                        # Flatten Data
                        nn.Flatten(),                        # Flatten
    
                        # feed forward Layers
                        nn.Linear(1024,256),                  # Linear 
                        nn.ReLU(True),                       # Activation
                        nn.Linear(256,43)                    # Linear 
                    )

model = model.to(torch.device('cuda'),non_blocking=True)
ts.summary(model,(3,32,32))


// 9.
def evaluate(model, data, target):
    data = data.to(torch.device('cuda'),non_blocking=True)
    target = target.to(torch.device('cuda'),non_blocking=True)
    length = len(target)
    yhat = model(data)
    ypred = yhat.argmax(axis=1)
    loss = float(nn.functional.cross_entropy(yhat, target)) 
    acc = float((ypred == target).sum() / length)
    print('Loss :',round(loss,4),'- Accuracy :',round(acc,4)) 
    del data,target,yhat,ypred
    torch.cuda.empty_cache()
    

// 10.
print('\nInitial Loss and Accuracy on Test Dataset :')
evaluate(model,xtest.float(),ytest)


// 11.
def train_model(model=model,optimizer=torch.optim.Adam,epochs=5,batch_size=200,steps_per_epochs=200,l2_reg=0,max_lr=0.01,grad_clip=0.5):
    
    hist = [[],[],[],[]] # hist will stores train and test data losses and accuracy of every epochs
    
    train_ds = [(x,y) for x,y in zip(xtrain,ytrain)] 
    training_dl = torch.utils.data.DataLoader(train_ds,batch_size=batch_size) 
    train_dl = torch.utils.data.DataLoader(train_ds,batch_size=batch_size * steps_per_epochs) 

    del train_ds 
    gc.collect() 
    
    optimizer = optimizer(model.parameters(),weight_decay=l2_reg)
    
    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr,epochs=epochs, steps_per_epoch=int(steps_per_epochs * 1.01))
        
    for i in range(epochs):
                 
        print('\nEpoch' , i+1 , ': [',end="")
        
        for j,(xb,yb) in enumerate(training_dl):
            
            xb = xb.to(torch.device('cuda'),non_blocking=True)
            yb = yb.to(torch.device('cuda'),non_blocking=True)
            
            yhat = model(xb.float())
            loss = nn.functional.cross_entropy(yhat, yb)
            loss.backward()
            
            nn.utils.clip_grad_value_(model.parameters(),grad_clip)
            
            optimizer.step()
            optimizer.zero_grad()
            
            sched.step()
            
            del xb,yb,yhat
            torch.cuda.empty_cache()
            
            if j % int(steps_per_epochs / 20) == 0:
                print('.',end='')
                
            if steps_per_epochs == j :
                break
                              
        device = torch.device('cuda') # initialized cuda to device
        
        for xtrainb,ytrainb in train_dl:
            break
        
        xtrain_cuda = xtrainb.to(device,non_blocking=True)
        ytrain_cuda = ytrainb.to(device,non_blocking=True)
        del xtrainb, ytrainb
        gc.collect()
        
        yhat = model(xtrain_cuda.float())
        ypred = yhat.argmax(axis=1)
        train_loss = float(nn.functional.cross_entropy(yhat, ytrain_cuda))
        train_acc = float((ypred == ytrain_cuda).sum() / len(ytrain_cuda))
        
        del xtrain_cuda, ytrain_cuda, yhat, ypred
        torch.cuda.empty_cache()
        
        xtest_cuda = xtest.to(device,non_blocking=True)
        ytest_cuda = ytest.to(device,non_blocking=True)
        
        yhat = model(xtest_cuda.float())
        ypred = yhat.argmax(axis=1)
        val_loss = float(nn.functional.cross_entropy(yhat, ytest_cuda))
        val_acc = float((ypred == ytest_cuda).sum() / len(ytest_cuda))
        
        del xtest_cuda, ytest_cuda, yhat, ypred
        torch.cuda.empty_cache()
        
        print('] - Train Loss :',round(train_loss,4),'- Train Accuracy :',round(train_acc,4),
              '- Val Loss :',round(val_loss,4), '- Val Accuracy :',round(val_acc,4))
        
        hist[0].append(train_loss)
        hist[1].append(val_loss)
        hist[2].append(train_acc)
        hist[3].append(val_acc)
        
    history = {'Train Loss':hist[0],'Val Loss':hist[1],'Train Accuracy':hist[2], 'Val Accuracy':hist[3]}
    
    return pd.DataFrame(history)
    

// 12.
%%time
history = train_model(model,optimizer=torch.optim.Adam,epochs=25,steps_per_epochs=200,l2_reg=0,max_lr=0.015,grad_clip=0.5)


// 13.
history


// 14.
fig = px.line(history.iloc[:,:2],title='Loss Per Epochs',labels={'value':'Loss','index':'Epochs'})
fig.update_layout(title={'font_family':'Georgia','font_size':23,'x':0.5}).show()
fig = px.line(history.iloc[:,2:],title='Accuracy Per Epochs',labels={'value':'Accuracy','index':'Epochs'})
fig.update_layout(title={'font_family':'Georgia','font_size':23,'x':0.5}).show() 


// 15.
xtest =  xtest.to(torch.device('cuda'),non_blocking=True)
ypred = model(xtest.float()).argmax(axis=1)
xtest = xtest.to(torch.device('cpu'),non_blocking=True)
ypred = ypred.to(torch.device('cpu'),non_blocking=True)
print(classification_report(ytest,ypred))


// 16.
def prediction(img):
    if type(img) == str:
        img = tv.transforms.ToTensor()(PIL.Image.open(img))
    img = cv2.resize(img.permute(1,2,0).numpy(),(32,32))
    img = torch.from_numpy(img).permute(2,0,1)
    img_tensor = img.unsqueeze(0).to(torch.device('cuda'))
    pred = int(model(img_tensor).argmax(axis=1)[0])
    pred_str = labels_df[labels_df['ClassId'] == pred]['Name'][pred]
    plt.figure(figsize=(5,5))
    plt.imshow(cv2.resize(img.permute(1,2,0).numpy(),(1000,1000)))
    plt.axis('off')
    print('\nRecognized Traffic Sign :',pred_str,'\n')
    
